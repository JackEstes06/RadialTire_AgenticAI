import json
import os
import smtplib
import pandas as pd
from datetime import datetime, timedelta
from typing import TypedDict
from dotenv import load_dotenv
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# LangChain / LangGraph Imports
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END

load_dotenv()

LOG_FILE = "query_logs.jsonl"

# --- 1. Define the State ---
class AgentState(TypedDict):
    days_back: int
    raw_questions: str
    
    # Analysis Outputs
    stats_analysis: str
    confusion_analysis: str
    recommendations: str    # "Informed" by previous steps
    
    final_report: str       # Generated by Compiler
    email_status: str

# --- 2. Setup the LLM ---
llm = ChatAnthropic(model="claude-3-haiku-20240307", temperature=0)

# --- 3. Define the Nodes ---

def load_data_node(state: AgentState):
    """Ingests logs, filters by date, and formats text for the agents."""
    days = state.get("days_back", 30)
    
    if not os.path.exists(LOG_FILE):
        return {"raw_questions": "No log file found."}

    data = []
    with open(LOG_FILE, 'r') as f:
        for line in f:
            try:
                data.append(json.loads(line))
            except:
                continue
    
    df = pd.DataFrame(data)
    
    # Filter by date window if timestamp exists
    if 'timestamp' in df.columns:
        df['date'] = pd.to_datetime(df['timestamp'], unit='s')
        cutoff = datetime.now() - timedelta(days=days)
        df = df[df['date'] > cutoff]
    
    questions = df['question'].tolist() if 'question' in df.columns else []
    
    if not questions:
        return {"raw_questions": "No questions found in range."}

    text_data = "\n".join([f"- {q}" for q in questions])
    return {"raw_questions": text_data}

def topic_analyzer_node(state: AgentState):
    """Analyzes raw text to identify the 'What' (Recurring Topics)."""
    print("   ... Analyzing Topics")
    prompt = ChatPromptTemplate.from_template(
        "Analyze these employee questions. List the Top 3 Recurring Topics with counts:\n\n{data}"
    )
    chain = prompt | llm
    response = chain.invoke({"data": state["raw_questions"]})
    return {"stats_analysis": response.content}

def confusion_analyzer_node(state: AgentState):
    """Analyzes raw text to identify the 'Why' (Technical Confusion)."""
    print("   ... Analyzing Confusion")
    prompt = ChatPromptTemplate.from_template(
        "Analyze these questions for specific technical confusion. What rules or models are misunderstood?\n\n{data}"
    )
    chain = prompt | llm
    response = chain.invoke({"data": state["raw_questions"]})
    return {"confusion_analysis": response.content}

def informed_recommendation_node(state: AgentState):
    """
    Acts as a Senior Consultant. 
    Reads the specific findings from previous agents to generate targeted fixes.
    """
    print("   ... Generating Recommendations")
    prompt = ChatPromptTemplate.from_template(
        """You are a Senior Technical Trainer. 
        Review the following analysis findings:
        
        TOPICS FOUND:
        {stats}
        
        CONFUSION POINTS:
        {confusion}
        
        Based ONLY on these findings, write 3 specific, high-impact training recommendations to fix these gaps.
        """
    )
    chain = prompt | llm
    response = chain.invoke({
        "stats": state["stats_analysis"],
        "confusion": state["confusion_analysis"]
    })
    return {"recommendations": response.content}

def report_compiler_agent_node(state: AgentState):
    """
    Acts as an AI Reporting System. 
    Formats the analysis into an objective executive summary and handles email delivery.
    """
    print("   ... Compiling Report")
    
    # 1. Generate the Executive Summary
    prompt = ChatPromptTemplate.from_template(
        """You are an automated AI Executive Reporting System.
        Your job is to format technical analysis into a clean, objective executive summary.
        
        INPUT DATA:
        1. Topics: {stats}
        2. Confusion: {confusion}
        3. Recommendations: {recs}
        
        STRICT FORMATTING RULES:
        1. Do NOT include a "Subject:" line.
        2. Do NOT use personal salutations (e.g., "Dear VP").
        3. Start directly with the header "EXECUTIVE TRAINING SUMMARY".
        4. Use bullet points and bold headers.
        5. Tone: Informative, neutral, non-conversational.
        6. END with exactly: "*** Report Generated by Automated AI Analytics Agent ***"
        
        Output ONLY the body text.
        """
    )
    chain = prompt | llm
    email_body = chain.invoke({
        "stats": state["stats_analysis"],
        "confusion": state["confusion_analysis"],
        "recs": state["recommendations"]
    }).content
    
    # 2. Execute Email Send
    sender = os.getenv("EMAIL_SENDER")
    password = os.getenv("EMAIL_PASSWORD")
    recipient = os.getenv("EMAIL_RECIPIENT")

    status = "Skipped (Config Missing)"
    if sender and password:
        try:
            msg = MIMEMultipart()
            msg['From'] = sender
            msg['To'] = recipient
            msg['Subject'] = f"Training Intelligence Report - {datetime.now().strftime('%B %Y')}"
            msg.attach(MIMEText(email_body, 'plain'))
            
            with smtplib.SMTP('smtp.gmail.com', 587) as server:
                server.starttls()
                server.login(sender, password)
                server.send_message(msg)
            status = "Sent Successfully"
        except Exception as e:
            status = f"Failed: {str(e)}"
            
    return {"final_report": email_body, "email_status": status}

# --- 4. Build the Graph ---

builder = StateGraph(AgentState)

# Add Nodes
builder.add_node("load_data", load_data_node)
builder.add_node("analyze_topics", topic_analyzer_node)
builder.add_node("analyze_confusion", confusion_analyzer_node)
builder.add_node("analyze_recommendations", informed_recommendation_node)
builder.add_node("compiler_agent", report_compiler_agent_node)

# Define Sequential Edges (Deep Reasoning Pipeline)
builder.add_edge(START, "load_data")
builder.add_edge("load_data", "analyze_topics")
builder.add_edge("analyze_topics", "analyze_confusion")
builder.add_edge("analyze_confusion", "analyze_recommendations")
builder.add_edge("analyze_recommendations", "compiler_agent")
builder.add_edge("compiler_agent", END)

app = builder.compile()

# --- 5. Execution ---

if __name__ == "__main__":
    print("ðŸš€ Starting Agentic Pipeline...")
    
    result = app.invoke({"days_back": 30})
    
    print(f"\nSTATUS: {result['email_status']}")
    print("\n--- FINAL AGENT REPORT ---\n")
    print(result['final_report'])